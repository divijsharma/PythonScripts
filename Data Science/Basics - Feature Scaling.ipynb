{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Feature Scaling?\n",
    "\n",
    "__Feature scaling__ is a method used to standardize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is Feature Scaling needed?\n",
    "The main advantage of scaling is to avoid attributes in greater numeric ranges dominating those in smaller numeric ranges. Scaling ensures that just because some features are __big__ (i.e. greater numeric ranges) it won't lead to using them as a __main predictor__. \n",
    "\n",
    "_We need Feature Scaling for **all techniques that use distances in any way**. We **must** perform feature scaling in **any technique that uses SGD (Stochastic Gradient Descent)**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which techniques need Feature Scaling?\n",
    "1. SVM (Support Vector Machines)\n",
    "2. kNN (k-Nearest Neighbors)\n",
    "3. PCA (Principal Component Analysis)\n",
    "4. Neural Networks **(must)**\n",
    "5. Logistic Regression **(must)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are different ways of Feature Scaling?\n",
    "1. Simple Feature Rescaling aka Rescaling aka min-max normalization aka  min-max scaling\n",
    "2. Mean Normalization\n",
    "3. Standardization\n",
    "4. Normalization\n",
    "5. Robust Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT\n",
    "### Scale train/test data separately, otherwise this will result in leaking data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Feature Rescaling aka Rescaling aka min-max normalization aka  min-max scaling\n",
    "\n",
    "It is the simplest method and consists in rescaling the range of features to scale the range in [0, 1] or [−1, 1]. Selecting the target range depends on the nature of the data. This method is **heavily influenced by outliers**. Formula is as follows - \n",
    "$$x' = \\frac{x - min(x)}{max(x) - min(x)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "In this method instead of subtracting $min(x)$, $average(x)$ is subtracted. The formula is $$x' = \\frac{x - avg(x)}{max(x) - min(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization\n",
    "\n",
    "In machine learning, we can handle various types of data, e.g. audio signals and pixel values for image data, and this data can include multiple dimensions. **Feature standardization makes the values of each feature in the data have zero-mean (when subtracting the mean in the numerator) and unit-variance.** This method is widely used for normalization in many machine learning algorithms (e.g., **support vector machines, logistic regression, and artificial neural networks**). The general method of calculation is to determine the distribution mean and standard deviation for each feature. Next we subtract the mean from each feature. Then we divide the values (mean is already subtracted) of each feature by its standard deviation.\n",
    "\n",
    "This method is used when data has many outliers, when we need data to have zero mean.\n",
    "\n",
    "The formula is as follows - \n",
    "$$x' = \\frac{x - \\bar{x}}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "In this method, every feature vector is scaled so that it has norm = 1. Usually we use L2 (euclidean) norm but we can also use others. This method is usually used when we are going to apply methods such as dot products on the feature vectors. Because this transformation does not depend on other points in your dataset, calling $.fit()$ has no effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "\n",
    "# this does nothing because this method doesn't 'train' on your data\n",
    "normalizer.fit(X_train)\n",
    "\n",
    "X_train = normalizer.transform(X_train)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Scaling\n",
    "The RobustScaler uses a similar method to the Min-Max scaler but it instead uses the interquartile range, rathar than the min-max, so that **it is robust to outliers**.\n",
    "\n",
    "This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile).\n",
    "\n",
    "The formula is as follows - $$x' = \\frac{x - Q_1(x)}{Q_3(x) - Q_1(x)}$$. This method uses less of the data for scaling so it’s more suitable for when there are outliers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
